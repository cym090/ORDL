data_dir: /home/cym/workspace/data/ISIC_demo

whole_class: 
close_class: 4
known_class: ${eval:"list(range(${dataset.close_class}))"}
# unknown_class: ${eval:"list(set(range(${dataset.whole_class}))-set(${dataset.known_class}))"}
resize: 224
crop: 224

train_dataset:
  _target_: utils.osr_dataset.CustomDataset
  # class_list: ${dataset.known_class}
  data_dir: ${dataset.data_dir}
  mode: train
  transform:
    - _target_: torchvision.transforms.Resize
      size: ${eval:"(${dataset.crop},${dataset.crop})"}
      # interpolation:
      #   _target_: utils.transforms.interpolation
      #   _args_:
      #     - "bicubic"
    - _target_: torchvision.transforms.RandomCrop
      size: ${eval:"(${dataset.crop},${dataset.crop})"}
      padding: ${eval:"int(4 / 32 * ${dataset.crop})"}
    - _target_: torchvision.transforms.RandomHorizontalFlip
    # - _target_: torchvision.transforms.ColorJitter
    #   brightness: 0.05
    #   contrast: 0.05
    - _target_: torchvision.transforms.ToTensor
    # - _target_: utils.transforms.normalize_transform
    #   _args_:
    #     - ${dataset.norm}

close_test_dataset:
  _target_: utils.osr_dataset.CustomDataset
  # class_list: ${dataset.known_class}
  data_dir: ${dataset.data_dir}
  mode: test
  transform:
    - _target_: torchvision.transforms.Resize
      size: ${eval:"(${dataset.crop},${dataset.crop})"}
      # interpolation:
      #   _target_: utils.transforms.interpolation
      #   _args_:
      #     - "bicubic"
    - _target_: torchvision.transforms.ToTensor

open_test_dataset:
  _target_: utils.osr_dataset.CustomDataset
  # class_list: ${dataset.unknown_class}
  data_dir: ${dataset.data_dir}
  mode: open
  transform:
    - _target_: torchvision.transforms.Resize
      size: ${eval:"(${dataset.crop},${dataset.crop})"}
      # interpolation:
      #   _target_: utils.transforms.interpolation
      #   _args_:
      #     - "bicubic"
    - _target_: torchvision.transforms.ToTensor

